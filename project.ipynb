{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ForestPearson/CS410-510-NLP-project/blob/Forest-Branch/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suR1yK_MgUwt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import StringLookup\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "EPOCHS = 30\n",
        "DIM = 256\n",
        "RNN = 1024\n",
        "\n",
        "#path = tf.keras.utils.get_file('input.txt', 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt')\n",
        "path = tf.keras.utils.get_file('alls_well_that_ends_well.txt', 'https://raw.githubusercontent.com/ForestPearson/CS410-510-NLP-project/Forest-Branch/data/alls_well_that_ends_well.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MO_gdgLYhjp0",
        "outputId": "ad2025ac-c42d-4ae6-e185-2157e6d2ee04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length: 129859\n",
            "ACT I\n",
            "\n",
            "SCENE I. Rousillon. The COUNT's palace.\n",
            "\n",
            "Enter BERTRAM, the COUNTESS of Rousillon, HELENA, and LAFEU, all in black\n",
            "COUNTESS\n",
            "In delivering my son from me, I bury a second husband.\n",
            "BERTRAM\n",
            "And I in going, madam, weep o'er my father's death\n",
            "anew: but I must attend his majesty's command, to\n",
            "whom I am now in ward, evermore in subjection.\n",
            "LAFEU\n",
            "You shall find of the king a husband, madam; you,\n",
            "sir, a father: he that so generally is at all times\n",
            "good must of necessity hold his virtue to you; who\n"
          ]
        }
      ],
      "source": [
        "text = open(path, 'rb').read().decode(encoding='utf-8')\n",
        "print(\"Length:\", len(text))\n",
        "print(text[:500])\n",
        "\n",
        "vocab = sorted(set(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50_P7GzQjlT1"
      },
      "outputs": [],
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "\n",
        "ids_from_chars = StringLookup(vocabulary=list(vocab), mask_token=None)\n",
        "chars_from_ids = StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
        "vocabSize = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "ids = ids_from_chars(chars)\n",
        "chars = chars_from_ids(ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZRNAQSwn2dn"
      },
      "outputs": [],
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orOMI3FImLsQ"
      },
      "outputs": [],
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "#Convert to character indices\n",
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
        "\n",
        "seq_length = 100\n",
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRXDSYnnoCJN",
        "outputId": "5d5423eb-d6c2-4896-d4de-949059f54de0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)\n",
        "dataset = (dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkcjqI8Opmyx"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,return_sequences=True,return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGvpyp38phUW"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocabSize,\n",
        "    embedding_dim=DIM,\n",
        "    rnn_units=RNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZH2Iawt1p8Cr",
        "outputId": "6c916a80-ae41-4617-9af5-56989bcdc061"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 100, 64) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNGsrLBFqsng"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
        "# Directory where the checkpoints will be saved\n",
        "dir = './data/epochs'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,save_weights_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMvVffRCrB_5",
        "outputId": "5aec0728-2329-4e94-b542-72acba4383bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 1.2210\n",
            "Epoch 2/30\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 1.1043\n",
            "Epoch 3/30\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 1.0448\n",
            "Epoch 4/30\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 0.9923\n",
            "Epoch 5/30\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.9351\n",
            "Epoch 6/30\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 0.8720\n",
            "Epoch 7/30\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 0.8087\n",
            "Epoch 8/30\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.7383\n",
            "Epoch 9/30\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 0.6701\n",
            "Epoch 10/30\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.5990\n",
            "Epoch 11/30\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 0.5270\n",
            "Epoch 12/30\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 0.4601\n",
            "Epoch 13/30\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.3980\n",
            "Epoch 14/30\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 0.3427\n",
            "Epoch 15/30\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.2909\n",
            "Epoch 16/30\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 0.2453\n",
            "Epoch 17/30\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 0.2105\n",
            "Epoch 18/30\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 0.1820\n",
            "Epoch 19/30\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 0.1588\n",
            "Epoch 20/30\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 0.1403\n",
            "Epoch 21/30\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.1255\n",
            "Epoch 22/30\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.1136\n",
            "Epoch 23/30\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 0.1039\n",
            "Epoch 24/30\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0958\n",
            "Epoch 25/30\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 0.0893\n",
            "Epoch 26/30\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0837\n",
            "Epoch 27/30\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0795\n",
            "Epoch 28/30\n",
            "20/20 [==============================] - 1s 41ms/step - loss: 0.0760\n",
            "Epoch 29/30\n",
            "20/20 [==============================] - 1s 40ms/step - loss: 0.0733\n",
            "Epoch 30/30\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 0.0707\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30b37Q7SxnEx"
      },
      "outputs": [],
      "source": [
        "class Generate(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  def predict(self, inputs, states=None):\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,return_state=True)\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    return predicted_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGb0wZUOxnEx",
        "outputId": "048faa93-07cb-4c08-dd2b-4d6fc8900434"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "COUNTESS:\n",
            "'To hundo in the boldness of his hald and sworn\n",
            "Do not talke her; but you must not be mine, I will he do for heary;\n",
            "Now his right be found in the enequare ten, was yours:\n",
            "Clown\n",
            "thy pathen's lack fortune fatch thy nose.\n",
            "Her that will you say, so stand upon your virginity,\n",
            "your old virginity, is like of loves, med compasitied\n",
            "By the king in the nextry than nature\n",
            "With him in gain, till she sighes; and be\n",
            "sin, of our felt-so't.\n",
            "HELENA\n",
            "Ay, surely. dear shief, I ither thing to speak\n",
            "our thousand ponsitious born brued him;\n",
            "But give thyself unto kine some scores was her wind.\n",
            "BERTRAM\n",
            "Athendance, of a most charkle our pours to chisder.\n",
            "Second Lord\n",
            "Brow him for what procesting him to\n",
            "resortion her his spurion, as\n",
            "in heaven we couns to shadl but that which\n",
            "I shall continue thankful.\n",
            "Gentleman\n",
            "I shall, my liege.\n",
            "Exit\n",
            "\n",
            "KING\n",
            "Thus he his special nothing ever prologues.\n",
            "Re-enter LAFEU, with like-\n",
            "PAROLLES guarded, and First Soldier\n",
            "\n",
            "BERTRAM\n",
            "Ay, sir, deliver it fills.\n",
            "DING\n",
            "Thus young leature as an ol \n",
            "\n",
            "________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "Generator = Generate(model, chars_from_ids, ids_from_chars)\n",
        "states = None\n",
        "seed = tf.constant(['COUNTESS:'])\n",
        "result = [seed]\n",
        "\n",
        "for n in range(1000):\n",
        "  seed, states = Generator.predict(seed, states=states)\n",
        "  result.append(seed)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "866cd1245b3823e185398c1063f44bf9b1cf162f43ea0435a9319e64a7104072"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}