{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ForestPearson/CS410-510-NLP-project/blob/Ray-Branch/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ixopy-lgAf3w"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "suR1yK_MgUwt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "a0GhfEpRArRq"
      },
      "outputs": [],
      "source": [
        "# load ascii text and covert to lowercase\n",
        "filename = \"input.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DMxEiLrZB24e"
      },
      "outputs": [],
      "source": [
        "...\n",
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Dxohx55hAvW0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25660f8b-972a-4da2-cb96-98d2c382bfbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Characters:  1115394\n",
            "Total Vocab:  39\n"
          ]
        }
      ],
      "source": [
        "...\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print( \"Total Characters: \", n_chars)\n",
        "print( \"Total Vocab: \", n_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Vj50k0FeAw7j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c9cc5b6-f94f-4816-f989-71b5acb5136a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns:  1115094\n"
          ]
        }
      ],
      "source": [
        "...\n",
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 300\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QMH3Ppv3AzP2"
      },
      "outputs": [],
      "source": [
        "\n",
        "...\n",
        "# reshape X to be [samples, time steps, features]\n",
        "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = to_categorical(dataY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "enUBSGqAA0eA"
      },
      "outputs": [],
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='sigmoid'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "No4Osk7EIy1k"
      },
      "outputs": [],
      "source": [
        "...\n",
        "# define the checkpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gazfkDXiYOn7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "035d1547-1487-426c-faef-b114da06c3ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/23\n",
            "2230/2231 [============================>.] - ETA: 0s - loss: 2.8484\n",
            "Epoch 1: loss improved from inf to 2.84842, saving model to weights-improvement-01-2.8484.hdf5\n",
            "2231/2231 [==============================] - 238s 103ms/step - loss: 2.8484\n",
            "Epoch 2/23\n",
            "2230/2231 [============================>.] - ETA: 0s - loss: 2.6314\n",
            "Epoch 2: loss improved from 2.84842 to 2.63143, saving model to weights-improvement-02-2.6314.hdf5\n",
            "2231/2231 [==============================] - 238s 107ms/step - loss: 2.6314\n",
            "Epoch 3/23\n",
            "2230/2231 [============================>.] - ETA: 0s - loss: 2.4994\n",
            "Epoch 3: loss improved from 2.63143 to 2.49937, saving model to weights-improvement-03-2.4994.hdf5\n",
            "2231/2231 [==============================] - 239s 107ms/step - loss: 2.4994\n",
            "Epoch 4/23\n",
            "2230/2231 [============================>.] - ETA: 0s - loss: 2.4151\n",
            "Epoch 4: loss improved from 2.49937 to 2.41510, saving model to weights-improvement-04-2.4151.hdf5\n",
            "2231/2231 [==============================] - 238s 107ms/step - loss: 2.4151\n",
            "Epoch 5/23\n",
            "2230/2231 [============================>.] - ETA: 0s - loss: 2.3510\n",
            "Epoch 5: loss improved from 2.41510 to 2.35099, saving model to weights-improvement-05-2.3510.hdf5\n",
            "2231/2231 [==============================] - 238s 107ms/step - loss: 2.3510\n",
            "Epoch 6/23\n",
            "2230/2231 [============================>.] - ETA: 0s - loss: 2.2980\n",
            "Epoch 6: loss improved from 2.35099 to 2.29802, saving model to weights-improvement-06-2.2980.hdf5\n",
            "2231/2231 [==============================] - 239s 107ms/step - loss: 2.2980\n",
            "Epoch 7/23\n",
            "2230/2231 [============================>.] - ETA: 0s - loss: 2.2533\n",
            "Epoch 7: loss improved from 2.29802 to 2.25334, saving model to weights-improvement-07-2.2533.hdf5\n",
            "2231/2231 [==============================] - 238s 107ms/step - loss: 2.2533\n",
            "Epoch 8/23\n",
            "2230/2231 [============================>.] - ETA: 0s - loss: 2.2150\n",
            "Epoch 8: loss improved from 2.25334 to 2.21495, saving model to weights-improvement-08-2.2149.hdf5\n",
            "2231/2231 [==============================] - 239s 107ms/step - loss: 2.2149\n",
            "Epoch 9/23\n",
            "2230/2231 [============================>.] - ETA: 0s - loss: 2.1821\n",
            "Epoch 9: loss improved from 2.21495 to 2.18204, saving model to weights-improvement-09-2.1820.hdf5\n",
            "2231/2231 [==============================] - 238s 107ms/step - loss: 2.1820\n",
            "Epoch 10/23\n",
            "2230/2231 [============================>.] - ETA: 0s - loss: 2.1531\n",
            "Epoch 10: loss improved from 2.18204 to 2.15306, saving model to weights-improvement-10-2.1531.hdf5\n",
            "2231/2231 [==============================] - 238s 107ms/step - loss: 2.1531\n",
            "Epoch 11/23\n",
            "2230/2231 [============================>.] - ETA: 0s - loss: 2.1269\n",
            "Epoch 11: loss improved from 2.15306 to 2.12695, saving model to weights-improvement-11-2.1269.hdf5\n",
            "2231/2231 [==============================] - 238s 107ms/step - loss: 2.1269\n",
            "Epoch 12/23\n",
            "2230/2231 [============================>.] - ETA: 0s - loss: 2.1047\n",
            "Epoch 12: loss improved from 2.12695 to 2.10463, saving model to weights-improvement-12-2.1046.hdf5\n",
            "2231/2231 [==============================] - 238s 107ms/step - loss: 2.1046\n",
            "Epoch 13/23\n",
            "2230/2231 [============================>.] - ETA: 0s - loss: 2.0834\n",
            "Epoch 13: loss improved from 2.10463 to 2.08348, saving model to weights-improvement-13-2.0835.hdf5\n",
            "2231/2231 [==============================] - 238s 107ms/step - loss: 2.0835\n",
            "Epoch 14/23\n",
            "2230/2231 [============================>.] - ETA: 0s - loss: 2.0665\n",
            "Epoch 14: loss improved from 2.08348 to 2.06654, saving model to weights-improvement-14-2.0665.hdf5\n",
            "2231/2231 [==============================] - 239s 107ms/step - loss: 2.0665\n",
            "Epoch 15/23\n",
            "2230/2231 [============================>.] - ETA: 0s - loss: 2.0488\n",
            "Epoch 15: loss improved from 2.06654 to 2.04880, saving model to weights-improvement-15-2.0488.hdf5\n",
            "2231/2231 [==============================] - 238s 107ms/step - loss: 2.0488\n",
            "Epoch 16/23\n",
            "2230/2231 [============================>.] - ETA: 0s - loss: 2.0333\n",
            "Epoch 16: loss improved from 2.04880 to 2.03327, saving model to weights-improvement-16-2.0333.hdf5\n",
            "2231/2231 [==============================] - 238s 107ms/step - loss: 2.0333\n",
            "Epoch 17/23\n",
            "2230/2231 [============================>.] - ETA: 0s - loss: 2.0208\n",
            "Epoch 17: loss improved from 2.03327 to 2.02080, saving model to weights-improvement-17-2.0208.hdf5\n",
            "2231/2231 [==============================] - 238s 107ms/step - loss: 2.0208\n",
            "Epoch 18/23\n",
            "2230/2231 [============================>.] - ETA: 0s - loss: 2.0074\n",
            "Epoch 18: loss improved from 2.02080 to 2.00737, saving model to weights-improvement-18-2.0074.hdf5\n",
            "2231/2231 [==============================] - 238s 107ms/step - loss: 2.0074\n",
            "Epoch 19/23\n",
            "2230/2231 [============================>.] - ETA: 0s - loss: 1.9947\n",
            "Epoch 19: loss improved from 2.00737 to 1.99467, saving model to weights-improvement-19-1.9947.hdf5\n",
            "2231/2231 [==============================] - 238s 107ms/step - loss: 1.9947\n",
            "Epoch 20/23\n",
            "2230/2231 [============================>.] - ETA: 0s - loss: 1.9827\n",
            "Epoch 20: loss improved from 1.99467 to 1.98266, saving model to weights-improvement-20-1.9827.hdf5\n",
            "2231/2231 [==============================] - 238s 107ms/step - loss: 1.9827\n",
            "Epoch 21/23\n",
            "2230/2231 [============================>.] - ETA: 0s - loss: 1.9838\n",
            "Epoch 21: loss did not improve from 1.98266\n",
            "2231/2231 [==============================] - 239s 107ms/step - loss: 1.9838\n",
            "Epoch 22/23\n",
            "2230/2231 [============================>.] - ETA: 0s - loss: 1.9630\n",
            "Epoch 22: loss improved from 1.98266 to 1.96302, saving model to weights-improvement-22-1.9630.hdf5\n",
            "2231/2231 [==============================] - 239s 107ms/step - loss: 1.9630\n",
            "Epoch 23/23\n",
            "2230/2231 [============================>.] - ETA: 0s - loss: 1.9557\n",
            "Epoch 23: loss improved from 1.96302 to 1.95570, saving model to weights-improvement-23-1.9557.hdf5\n",
            "2231/2231 [==============================] - 239s 107ms/step - loss: 1.9557\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f86785e14d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "model.fit(X, y, epochs=23, batch_size=500, callbacks=callbacks_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4dVGDBCoVsk_"
      },
      "outputs": [],
      "source": [
        "# load the network weights\n",
        "filename = \"weights-improvement-23-1.9557.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GtQhP7gbWm9-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "972125dd-0cbf-4eca-f9e3-d257f302f687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed:\n",
            "\" t got it, if thou hast\n",
            "the ordering of the mind too, 'mongst all colours\n",
            "no yellow in't, lest she suspect, as he does,\n",
            "her children not her husband's!\n",
            "\n",
            "leontes:\n",
            "a gross hag\n",
            "and, lozel, thou art worthy to be hang'd,\n",
            "that wilt not stay her tongue.\n",
            "\n",
            "antigonus:\n",
            "hang all the husbands\n",
            "that cannot do that  \"\n",
            "the matter of the cattee\n",
            "and the case of the catte to the case of the catte\n",
            "that ia the terte that ia the tiree toa the wirless of the caat of the cattee thene the cattee of the cattee\n",
            "of the tooeue of the catte of the casest sartert\n",
            "that the mar have benneved the sooe that ha the mane\n",
            "the matter of the sireer of the world thene\n",
            "that ha the marter of the sarter of the couste\n",
            "of the case of the catte of the casest sartert\n",
            "that the mar have benneved the sooe that ha the mane\n",
            "the matter of the wirlens of the world the catte\n",
            "the rartine of the wirlens of the wirless\n",
            "of the world sare the catte of the casest sareer\n",
            "that the mar have benneved the sooe that have aelit\n",
            "the partien of the world that have aelit\n",
            "the partien of the wirlens of the wirless\n",
            "of the world sare the catte of the casest sareer\n",
            "that ia the tiree that have benne the world,\n",
            "and thene the sireer that ia ho the soeees,\n",
            "and thene the sireet sarter of the wirless\n",
            "of the world sare the sarter of the wirless\n",
            "of the world sare the \n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "...\n",
        "# pick a random seed\n",
        "start = np.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "\tx = np.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = np.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2BPh3ssVtre"
      },
      "source": [
        "# New Section"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}